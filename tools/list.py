#!/usr/bin/env python3
"""
è·å– B ç«™è§†é¢‘åˆ—è¡¨ (ç¨åå†çœ‹/æ”¶è—å¤¹)

ç”¨æ³•:
    python tools/list.py --watch-later --browser edge --limit 10
"""

import argparse
import json
import subprocess
import os
import sys
import requests
from pathlib import Path


def export_cookies_from_browser(browser_name, output_file):
    """ä½¿ç”¨ yt-dlp ä»æµè§ˆå™¨å¯¼å‡º Cookie"""
    print(f"ğŸª æ­£åœ¨ä» {browser_name} å¯¼å‡º Cookie...")
    cmd = [
        "yt-dlp",
        "--cookies-from-browser", browser_name,
        "--cookies", str(output_file),
        "--skip-download",
        "https://www.bilibili.com",
    ]
    
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        return True
    except subprocess.CalledProcessError:
        print(f"âŒ æ— æ³•ä» {browser_name} è¯»å– Cookieã€‚è¯·ç¡®ä¿æµè§ˆå™¨å·²å…³é—­æˆ–æœªè¢«å ç”¨ã€‚")
        return False
    except FileNotFoundError:
        print("âŒ æœªæ‰¾åˆ° yt-dlp")
        return False


def parse_netscape_cookies(cookie_file):
    """è§£æ Netscape æ ¼å¼ Cookie æ–‡ä»¶åˆ° dict"""
    cookies = {}
    with open(cookie_file, 'r') as f:
        for line in f:
            if line.startswith('#') or not line.strip():
                continue
            parts = line.split('\t')
            if len(parts) >= 7:
                cookies[parts[5]] = parts[6].strip()
    return cookies


def get_watch_later(cookies, limit=10):
    """è·å–ç¨åå†çœ‹åˆ—è¡¨"""
    url = "https://api.bilibili.com/x/v2/history/toview"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Referer": "https://www.bilibili.com/"
    }
    
    resp = requests.get(url, cookies=cookies, headers=headers)
    data = resp.json()
    
    if data["code"] != 0:
        print(f"âŒ API è¯·æ±‚å¤±è´¥: {data.get('message')}")
        return []
    
    videos = data["data"]["list"]
    return videos[:limit]


def main():
    parser = argparse.ArgumentParser(description="è·å– B ç«™è§†é¢‘åˆ—è¡¨")
    parser.add_argument("--watch-later", "-wl", action="store_true", help="è·å–ç¨åå†çœ‹")
    parser.add_argument("--browser", "-b", help="ä»æµè§ˆå™¨è¯»å– Cookie (edge, chrome)")
    parser.add_argument("--limit", "-n", type=int, default=10, help="æ•°é‡é™åˆ¶")
    
    args = parser.parse_args()
    
    cookie_file = Path(".temp_cookies.txt")
    cookies = {}
    
    # 1. è·å– Cookie
    if args.browser:
        if export_cookies_from_browser(args.browser, cookie_file):
            cookies = parse_netscape_cookies(cookie_file)
            cookie_file.unlink()
    else:
        # å°è¯•åŠ è½½ auth.py ä¿å­˜çš„ session
        sys.path.insert(0, str(Path(__file__).parent))
        try:
            from auth import get_cookies
            cookies = get_cookies()
            if cookies:
                print("   è®¤è¯: ä½¿ç”¨ä¿å­˜çš„ Session âœ…")
        except ImportError:
            pass

    if not cookies:
        print("âŒ æœªè·å–åˆ°æœ‰æ•ˆ Cookieï¼Œæ— æ³•è®¿é—®ç§æœ‰åˆ—è¡¨")
        return

    # 2. è·å–åˆ—è¡¨
    if args.watch_later:
        print(f"ğŸ“‹ æ­£åœ¨è·å–â€˜ç¨åå†çœ‹â€™åˆ—è¡¨ (å‰ {args.limit} ä¸ª)...")
        videos = get_watch_later(cookies, args.limit)
        
        if not videos:
            print("   åˆ—è¡¨ä¸ºç©ºæˆ–è·å–å¤±è´¥")
            return
            
        print(f"âœ… è·å–åˆ° {len(videos)} ä¸ªè§†é¢‘:")
        for v in videos:
            print(f"   - [{v['bvid']}] {v['title']}")
            
        # è¾“å‡º JSON ä¾›å…¶ä»–å·¥å…·è°ƒç”¨
        with open("batch_list.json", "w") as f:
            json.dump(videos, f, ensure_ascii=False, indent=2)
        print("\nğŸ’¾ åˆ—è¡¨å·²ä¿å­˜åˆ° batch_list.json")

if __name__ == "__main__":
    main()
